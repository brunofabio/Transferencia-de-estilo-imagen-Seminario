{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # Libreria numpy\nimport pandas as pd # procesamiento de data, archivos CSV I/O (e.g. pd.read_csv)\n\n# Los archivos de entrada están disponibles en el directorio \"../input/\".\n# Por ejemplo, listado de los archivos en el directorio input\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Cualquier resultado que se escriba en el presente directorio será guardado como salida.\n%matplotlib inline\n\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf, pdb\nimport PIL\nimport matplotlib.image as mpimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c24691e1ea567076ab55d0e13164bbdcb738bb71"},"cell_type":"code","source":"WEIGHTS_INIT_STDEV = .1\n\ndef net(image):\n    conv1 = _conv_layer(image, 32, 9, 1)\n    conv2 = _conv_layer(conv1, 64, 3, 2)\n    conv3 = _conv_layer(conv2, 128, 3, 2)\n    resid1 = _residual_block(conv3, 3)\n    resid2 = _residual_block(resid1, 3)\n    resid3 = _residual_block(resid2, 3)\n    resid4 = _residual_block(resid3, 3)\n    resid5 = _residual_block(resid4, 3)\n    conv_t1 = _conv_tranpose_layer(resid5, 64, 3, 2)\n    conv_t2 = _conv_tranpose_layer(conv_t1, 32, 3, 2)\n    conv_t3 = _conv_layer(conv_t2, 3, 9, 1, relu=False)\n    preds = tf.nn.tanh(conv_t3) * 150 + 255./2\n    return preds\n\ndef _conv_layer(net, num_filters, filter_size, strides, relu=True):\n    weights_init = _conv_init_vars(net, num_filters, filter_size)\n    strides_shape = [1, strides, strides, 1]\n    net = tf.nn.conv2d(net, weights_init, strides_shape, padding='SAME')\n    net = _instance_norm(net)\n    if relu:\n        net = tf.nn.relu(net)\n\n    return net\n\ndef _conv_tranpose_layer(net, num_filters, filter_size, strides):\n    weights_init = _conv_init_vars(net, num_filters, filter_size, transpose=True)\n\n    batch_size, rows, cols, in_channels = [i.value for i in net.get_shape()]\n    new_rows, new_cols = int(rows * strides), int(cols * strides)\n    # new_shape = #tf.pack([tf.shape(net)[0], new_rows, new_cols, num_filters])\n\n    new_shape = [batch_size, new_rows, new_cols, num_filters]\n    tf_shape = tf.stack(new_shape)\n    strides_shape = [1,strides,strides,1]\n\n    net = tf.nn.conv2d_transpose(net, weights_init, tf_shape, strides_shape, padding='SAME')\n    net = _instance_norm(net)\n    return tf.nn.relu(net)\n\ndef _residual_block(net, filter_size=3):\n    tmp = _conv_layer(net, 128, filter_size, 1)\n    return net + _conv_layer(tmp, 128, filter_size, 1, relu=False)\n\ndef _instance_norm(net, train=True):\n    batch, rows, cols, channels = [i.value for i in net.get_shape()]\n    var_shape = [channels]\n    mu, sigma_sq = tf.nn.moments(net, [1,2], keep_dims=True)\n    shift = tf.Variable(tf.zeros(var_shape))\n    scale = tf.Variable(tf.ones(var_shape))\n    epsilon = 1e-3\n    normalized = (net-mu)/(sigma_sq + epsilon)**(.5)\n    return scale * normalized + shift\n\ndef _conv_init_vars(net, out_channels, filter_size, transpose=False):\n    _, rows, cols, in_channels = [i.value for i in net.get_shape()]\n    if not transpose:\n        weights_shape = [filter_size, filter_size, in_channels, out_channels]\n    else:\n        weights_shape = [filter_size, filter_size, out_channels, in_channels]\n\n    weights_init = tf.Variable(tf.truncated_normal(weights_shape, stddev=WEIGHTS_INIT_STDEV, seed=1), dtype=tf.float32)\n    return weights_init","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"071c55bff6c7cafa46e6b0a96a1af2dc8fb2cef9"},"cell_type":"code","source":"def save_image(image, file_path):\n    '''\n    Guarda una imagen como un archivo jpg file. La imagen es dada como \n    un array numpy con valores de píxeles entre 0 y 255.\n    \n    :param image:\n        El array numpy de la imagen.\n        type: ndarray\n    :param file_path:\n        La ruta completa para guardar la imagen mezclada, \n        es decir, image path + image name\n        type: str\n    :return:\n        Guardar la imagen con un archivo jpeg.\n    '''\n    \n    # Asegurar que los valores de píxeles están entre 0 y 255.\n    image = np.clip(image, 0.0, 255.0)\n    \n    # Convertir a bytes.\n    image = image.astype(np.uint8)\n    \n    # Escribir el archivo imagen en el formato jpeg.\n    with open(file_path, 'wb') as file:\n        PIL.Image.fromarray(image).save(file, 'jpeg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad3c9c0e3c9c35f9c9340cce400da5422f1d114d"},"cell_type":"code","source":"def feed_forward(image_path, output_path, checkpoint_dir, style_path=None):\n    '''\n    Como ya tenemos un punto de control pre-entrenado, podemos usarlo \n    para generar una imagen mixta.\n    \n    :param image_path:\n        La ruta y el nombre del archivo que va ser transferido.\n        type: str\n    :param style_path:\n        La ruta y nombre de archivo de la imagen estilo.\n        Esto es solo para mostrar y no tiene nada que ver con el \n        procesamiento.\n        type: str\n    :param output_path:\n        La ruta para almacenar la imagen mixta, incluyendo su nombre de archivo.\n        type: str\n    :param checkpoint_dir:\n        La ruta y nombre de archivo del punto de control pre-entrenado.\n        type: str\n    :return:\n        Guarda la imagen mixta y la muestra.\n    '''\n    \n    # Construye un graph y una sesión.\n    with tf.Graph().as_default(), tf.Session() as sess:\n        # Lee la imagen contenido desde un archivo como un array numpy.\n        content_image = mpimg.imread(image_path)\n        \n        # Lee la imagen estilo desde un archivo si se proporciona.\n        if style_path is not None:\n            style_image = mpimg.imread(style_path)\n        \n        # Dado que la red de transformación de imagen requiere una matriz 4-D,\n        # Se tendrá que expandir una dimensión en el eje = 0.\n        content_image = np.expand_dims(content_image, axis=0)\n        \n        # Define un marcador de posición 4-D para la imagen.\n        image_holder = tf.placeholder(\n            tf.float32, content_image.shape, 'input_image')\n        \n        # Deja que la imagen fluya a través de la red de transformación.\n        output_image = net(image_holder)\n        \n        # Restaura el punto de control pre-entrenado.\n        saver = tf.train.Saver()\n        saver.restore(sess, checkpoint_dir)\n        \n        # Ejecuta la sesión.\n        feed_dict = {image_holder: content_image}\n        mixed_image = sess.run(output_image, feed_dict)\n        \n        # Guarda la imagen mixta.\n        with open(output_path, 'wb') as file:\n            save_image(mixed_image[0], output_path)\n        \n        # Si la imagen estilo es proporcionada, mostrar la imagen contenido, mixta y estilo.\n        if style_path is not None:\n            fig, axes = plt.subplots(1, 3, figsize=(20, 20))\n            \n        # Si la imagen estilo no es proporcionada, moestrar la imagen contenido y mixta.\n        else:\n            fig, axes = plt.subplots(1, 2, figsize=(20, 20))\n        \n        # Usa la interpolación para suavizar los píxeles.\n        smooth = True\n\n        # Tipo de interpolación.\n        if smooth:\n            interpolation = 'sinc'\n        else:\n            interpolation = 'nearest'\n            \n        # Grafica la imagen contenido.\n        # Notar que los valores de los píxeles son normalizados al rango\n        # [0.0, 1.0] dividiendo con 255.\n        ax = axes.flat[0]\n        ax.imshow(content_image[0] / 255.0, interpolation=interpolation)\n        ax.set_xlabel('Contenido')\n\n        # Grafica la imagen mixta.\n        ax = axes.flat[1]\n        ax.imshow(mixed_image[0] / 255.0, interpolation=interpolation)\n        ax.set_xlabel('Mixta')\n        \n        if style_path is not None:\n            # Grafica la imagen estilo\n            ax = axes.flat[2]\n            ax.imshow(style_image / 255.0, interpolation=interpolation)\n            ax.set_xlabel(\"Estilo\")\n        \n        # Elimina las marcas de todos los gráficos.\n        for ax in axes.flat:\n            ax.set_xticks([])\n            ax.set_yticks([])\n\n        # Asegura de que el gráfico se muestra correctamente con múltiples gráficos\n        # en una celda simple del Notebook.\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ebd1ed21577ec723475908494ecc18fe1c5550f"},"cell_type":"code","source":"INPUT_PATH = '../input/facultad1.jpg'\nOUTPUT_PATH = 'facultad1.jpg'\nCHECKPOINT_DIR = '../input/la_muse.ckpt'\nSTYLE_PATH = '../input/la_muse.jpg' # Opcional. Solo para mostrarlo.\n\n# Ejecuta el código.\nfeed_forward(INPUT_PATH, OUTPUT_PATH, CHECKPOINT_DIR, STYLE_PATH)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}